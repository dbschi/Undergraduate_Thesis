%\section{Guth-Maynard's proof of Large Values of Dirichlet Polynomials}
In May 2024, Guth and Maynard published an improvement of the large values of Dirichlet polynomails estimate at $\sigma\in[7/10,8/10]$.
\begin{theorem}[Guth-Maynard Large Values Estimate]
    Let $(b_n)$ be a sequence of complex numbers such that $|b_n|\leq 1$ for all $n$, and $W=\{t_j\}_{j=1}^{|W|}$ be a $1$-separated set $\subseteq [0,T]$, such that \[
    \left|\sum_{n\sim N}b_n n^{it_j}\right|\geq V
    \]
    for each $t_j\in W$. Then \[
    |W|\lesssim N^2V^{-2}+N^{18/5}V^{-4}+TN^{12/5}V^{-4}.
    \]
\end{theorem}
Let us compare this bound to Lemma \ref{halasz}, which states \[
|W|\lesssim N^2V^{-2}+TN^4V^{-6}.
\]
In the critical case $V=N^{3/4}, N\leq T^{5/6-\epsilon}$, the original bound will give \[
|W|\lesssim N^2N^{-3/2}+TN^4N^{-9/2}\lesssim N^{1/2}+ TN^{-1/2}\lesssim TN^{-1/2},
\]
while the bound by Guth and Maynard gives \[
|W|\lesssim N^2N^{-3/2}+N^{18/5}N^{-3}+TN^{12/5}N^{-3}\lesssim N^{1/2}+TN^{-3/5}\lesssim TN^{-3/5}.
\]
This new theorem, when applied in Huxley's proof in the previous chapter, gives an improvement in the bound of zero density in the range $\sigma\in[7/10,8/10]$.
\section{Outline and Sketch of proof}
%\node[label=above/below/etc:{label}] (x) {}
The structure of the proof can be broken down as follows: We first notice that $|W|$ is bounded by the operator norm of a matrix $M$. This operator norm, using results from linear algebra, is bounded by the trace. Applying Poisson summation on the trace gives $4$ terms that are separately handled, which we will name $S_0$ to $S_3$. We will see that $S_0$ gives the `main term' that is consistent with the density hypothesis, $S_1$ is negligible, $S_2$ is bounded by a theorem by Heath-Brown, which we state below. 
\begin{theorem}[Heath-Brown]
    \label{heathbrown}
    Let $\mathcal{S}=\{(t_j,\chi_j)\}$ be one-separate, primitive characters of modulus $q$. Then 
    \[
        \sum_{\substack{(t_1,\chi_1)\\(t_2,\chi_2)}}\left|\sum_{n=1}^{N} b_n n^{-i(t_1-t_2)}\chi_1\bar{\chi}_2(n)\right|^2 \lesssim  |\mathcal{S}|N^2+ |\mathcal{S}|^2N + |\mathcal{S}|^{5/4}(qT)^{1/2}N.
    \]
\end{theorem}
The most tricky term, $S_3$ is a summation over a three-dimensional lattice. We will see that $S_3$ is bounded by what is known as the \textit{additive energy} of the set $W$, defined by\[
    E(W)\defeq \#\{t_1,t_2,t_3,t_4\in W : |t_1+t_2-t_3-t_4|\ll T^\epsilon\}.
\]
This term describes the `additive structure' of $W$.
We see that $E(W)$ is bounded below by $|W|^2$, as the condition is satisfied when $t_1=t_3$ and $t_2=t_4$. Moreover, since $W$ is $1-separated$, the choice of $t_1,t_2,t_3$ fixes $O(1)$ choices for $t_4$, so $E(W)$ is bounded above by $|W|^3$. In the extreme case that the additive structure of $W$ is high, such as when $t_j=j\alpha$ for a constant $\alpha$, the energy of the set is $O(|W|^3)$. This definition naturally arrises from taking the fourth moment of the function \[
R(v)\defeq\sum_{t\in W} v^{it}.
\] 
This gives us \[
R(v)^4=\sum_{t_1,t_2,t_3,t_4\in W}v^{i(t_1+t_2-t_3-t_4)}.
\]

The naive choice $E(W)\leq W^3$ is slightly too loose to beat the Ingham-Huxley bound. However, an orthogonal bound can be found for $E(W)$ based on Heath-Brown's theorem. Finally, the bound in $7$ and $8$ combined is enough to give an improvement in most cases, a further refinement of the $S_3$ bound was required. This relies on the averaging over the affine summations of $R$.
 \[
        \sup_{0<M_1,M_2,M_3<M} \int\Bigg( \sum_{\substack{|m_1|\sim M_1\\|m_2|\sim M_2 \\ |m_3|\ll M_3}} \left|R\left(\frac{m_1 u+m_3}{m_2}\right)\right|\Bigg)^2 \ du \lesssim M^6 \|R\|_{L_2}^4+M^4\|f\|_{L_4}^4.
\] 

We give a quick sketch of the whole proof below. In the next section, we will give a full proof of the generalized statement of the theorem that considers primitive Dirichlet characters mod $q$. The proof of Guth-Maynard can be recovered by using the special case $q=1$.

\begin{figure} [t]
    \begin{tikzpicture}
        \begin{scope}[every node/.style={circle,thick,draw}]
            \node [label={[align=right]left:{$|W|$ is bounded by the operator\\ norm of a matrix $M$}}](A) at (0,0) {1};
            \node [label={[align=right]left:{$\|M\|^2$ is bounded by \\$\textrm{Tr}((M^*M)^k)^{1/k}$}}](B) at (0,-2) {2};
            \node [label={[align=right]left:{Poisson summation on $\textrm{Tr}((M^*M)^3)$,\\split in $4$ pieces}}](C) at (0,-4) {3};
            \node [label={[align=right] left:{$S_0$ gives main \\ term $N^2V^{-2}$}}](D) at (-6,-7) {4};
            \node [label={[align=right] left:{$S_1$ is negligible}}](E) at (-2,-7) {5};
            \node [label={[align=right] left:{$S_2$ reduces to\\ Heath-Brown}}](F) at (2,-7) {6};
            \node [label={[align=right] left:{$S_3$ is bounded\\ by Energy}}](G) at (6,-7) {7};
            \node [label={[align=right]left:{Energy bounded by \\ Heath-Brown}}](H) at (6,-10) {8};
            \node [label={[align=right]left:{Refinement of \\ $S_3$ bound}}](I) at (4,-8.5) {9};
        \end{scope}
        %\draw [dotted] (a) --  (b);
        \draw [->](A) -- (B);\draw [->](B) -- (C);
        \path [->](C) edge [bend left =13](D); \draw [->](C) -- (E); \draw [->](C) -- (F); \path [->](C) edge[bend left =20] (G);
        \draw[->] (G)--(H);\draw[->,red,dotted,thick] (G)--(I);\draw[dotted, red,->,thick] (I)--(H);
        %\draw (a) -- node[midway, below left]{1}(d) -- node[midway, below right]{2}(b);
        %\draw (a)-- node[midway, above left]{2} (c) --node[midway, above right]{1}(b);
\end{tikzpicture}
\caption{Graphical representation of Guth-Maynard proof outline}
\end{figure}
\subsubsection*{0. Setup}
First, as in the theorem, we let $(b_n)$ be a sequence of complex numbers such that $|b_n|\leq 1$ for all $n$, \[
D_n(t)\defeq \sum_{n\sim N}b_n n^{it},
\] $W=\{t_j\}_{j=1}^{|W|}$ be a $T^\epsilon$-separated set $\subseteq [0,T]$, such that \[
\left|D_n(t_j)\right|\geq V
\]
for each $t_j\in W$. Notice that we now let the set be $T^\epsilon$ separated for $\epsilon>0$. This means that we will give up a factor of $T^\epsilon$ in the final bound, but this makes many computations cleaner as this $T^\epsilon$ dominates the log factors. Moreover, we can introduce a bump function $\omega$ with support in $[1,2]$ to localize the summation, and rewrite \[
    D_n(t_j)=\sum_{n}\omega\left(\frac{n}{N}\right)b_n n^{it_j}.
\]
This is added for the Poisson summation in step $3$.
\subsubsection*{1. Bounding $|W|$ with operator norm}
We view $\vec{b}=(b_n)_{n\sim N}$ as a $N$-dimensional vector, and consider the $|W|\times N$ matrix, indexed by $j$ from $1$ to $|W|$ and $n\sim N$,\[
    M_{j,n}=n^{it_j}= \omega\left(\frac{n}{N}\right)n^{i t_j}.
\]
Then we can view the $j$-th entry of the product $M\vec{b}$ as $D_n(t_j)$. In other words \[
|M\vec{b}|^2\geq V^2{|W|}.
\]
However, we can bound $|M\vec{b}|$ using the operator norm of $M$ and $|b_n|\leq 1$ to get\[
    |M\vec{b}|^2\leq \|M\|^2|\vec{b}|^2 \leq \|M\|^2 N.
\]
Combined with the previous inequality, we get \begin{equation}
    \label{basicineq}
|W|\leq \|M\|^2 NV^{-2}.
\end{equation}

\subsubsection*{2. Bounding $\|M\|$}
An immediate way to proceed is to note that $\|M\|^2$ is the largest eigenvalue of $MM^*$, which in turn is bounded by sum of eigenvalues which is the trace of $M^*M$. However, this is somewhat inefficient. Consider $N$-dimensional vector that enumerates through the eigenvalues $(\lambda_n)$ of $MM^*$, so that the trace will be the $L_1$ norm of this vector. In principle, we would like the $L_{\infty}$ norm of this vector, so we can try to take $L_k$ norms of this vector for big $k$ to get close to $L_\infty$. Using an eigenbasis for $MM^*$, we can see that the $L_k$ norm is represented by \[
\left(\sum_{n\sim N}\lambda_n ^ {k}\right)^{1/k}= \textrm{Tr}((MM^*)^k)^{1/k}.
\]
We take $k=3$, which is the highest power we can afford given the tools at our disposal. This gives

\begin{equation}
    \label{traceineq}
    |W|\leq \textrm{Tr}((MM^*)^3)^{1/3} NV^{-2}.
\end{equation}

\subsubsection*{3. Expansion of $\rm{Tr}((MM^*)^3)$}
We first compute 

\begin{align*}
    (MM^*)_{n_1,n_2} = \sum_{t\in W} \omega\left(\frac{n_1}{N}\right)\omega\left(\frac{n_2}{N}\right)
    n_1^{-it_j}n_2^{it_j}
\end{align*}
so that\begin{align*}
    \textrm{tr}((M^*M)^3)=& \sum_{t_1,t_2,t_3\in W}\sum_{n_1,n_2,n_3\sim N} 
    \omega\left(\frac{n_1}{N}\right)^2\omega\left(\frac{n_2}{N}\right)^2\omega\left(\frac{n_3}{N}\right)^2 n_1^{i(t_1-t_3)}
   n_2^{i(t_2-t_1)}
    n_3^{i(t_3-t_2)}\\=& \sum_{t_1,t_2,t_3\in W}\sum_{n_1,n_2,n_3} 
    \omega\left(\frac{n_1}{N}\right)^2\omega\left(\frac{n_2}{N}\right)^2\omega\left(\frac{n_3}{N}\right)^2 \left(\frac{n_1}{N}\right)^{i(t_1-t_3)}
    \left(\frac{n_2}{N}\right)^{i(t_2-t_1)}
    \left(\frac{n_3}{N}\right)^{i(t_3-t_2)}.
\end{align*}
Let $h_t(u)\defeq \omega(u)^2 u^{it}$, we can apply Poisson summation in the inner integral over $n_1,n_2,n_3$ to get 
\begin{equation}\label{poissongm}
    \rm{tr}((M^*M)^3)= N^3\sum_{t_1,t_2,t_3\in W}\sum_{m_1,m_2,m_3}  \hat{h}_{t_1-t_3}(Nm_1)\hat{h}_{t_2-t_1}(Nm_2)\hat{h}_{t_3-t_2}(Nm_3).
\end{equation}
What we can gain here is that $\hat{h}_t{m}$ has decay in $t$ or $m$ based on the principle of non-stationary phase. 
\begin{lemma}[Non-stationary phase]
    \label{nonstationary}
    We have for any integer $A>0$\begin{align*}
        |\hat{h}_t(\xi)|\ll_A \frac{1+|t|^A}{|\xi|^A},\\
        |\hat{h}_t(\xi)|\ll_A \frac{1+|\xi|^A}{|t|^A}. 
    \end{align*}
\end{lemma}
\begin{proof}
   We have \[
   \hat{h}_t(\xi)=\int \omega(u)^2u^{it}e^{2\pi i \xi u} du.\]
   By repeated integration by parts on $\omega(u)^2u^{it}$ and $e^{2\pi i \xi u}$, we get \[
    |\hat{h}_t(\xi)|=\left|\int (2\pi i \xi)^{-A} e^{2\pi i \xi u}  \frac{d^A}{(du)^A}\left(\omega^2(u)u^{it}\right) du\right| \ll_A \frac{1+|t|^A}{|\xi|^A}.
   \]
   A similar argument for integration by parts on $\omega(u)^2e^{2\pi i \xi u}$ and $u^{it}$ gives \[
    |\hat{h}_t(\xi)|=\left|\int \frac{1}{(it+1)(it+2)\ldots(it+A)}u^{it+A}  \frac{d^A}{(du)^A}\left(\omega^2(u)e^{2\pi i \xi u}\right) du \right|\ll_A \frac{1+|\xi|^A}{|t|^A}.
   \]
\end{proof}
This means that we can handle terms in equation \ref{poissongm} if $m_i$ is small and $t_j-t_k$ is big, or  $m_i$ is big and $t_j-t_k$ is small. With this in mind, we split the sum over $m_1,m_2,m_3$ in the equation into four parts. $S_0$, where all three $m$ terms are zero, $S_1$, where exactly one of the $m$ terms is non-zero, $S_2$, where exactly two of the $m$ terms are non-zero, and $S_3$, where all three $m$ terms are non-zero.
That is,

\[\rm{tr}((M^*M)^3)= S_0+S_1+S_2+S_3, \]
where \[
S_j = N^3\sum_{m_1,m_2,m_3, \#\{m_k=0\}=j} I_m,
\]
\[
I_m=I_{(m_1,m_2,m_3)}\defeq N^3\sum_{t_1,t_2,t_3\in W}\hat{h}_{t_1-t_3}(Nm_1)\hat{h}_{t_2-t_1}(Nm_2)\hat{h}_{t_3-t_2}(Nm_3).
\]

\subsubsection*{4. Bounding $S_0$}
$S_0$ only has one term in the sum. \[
S_0 = N^3\sum_{t_1,t_2,t_3\in W} \hat{h}_{t_1-t_3}(0)\hat{h}_{t_2-t_1}(0)\hat{h}_{t_3-t_2}(0)
\]
Now we can apply that $W$ is $T^\epsilon$ separated, so there is a trivial bound $|W|\leq T$ and $\hat{h}_{t_j-t_k}$ is negligible by the principle of non-stationary phase. So we can only consider \[
S_0 = N^3\sum_{t\in W}\hat{h}_0(0) + O(T^{-100}) = N^3|W|\|\omega\|_{L_2}^6.
\]Taking the cube root, this term gives $O(N^2V^{-2}|W|)$ in equation \ref{traceineq}. This is strikingly similar to the $N^2V^{-2}$ term that the density hypothesis conjectures. Guth and Maynard isolates this term by introducing the following lemma.
\begin{lemma}\label{gmtrace}
    Let $A$ be an $m\times n$ matrix. Then 
    \[\|A\| \leq 2\left(\rm{tr}((AA^*)^3)-\frac{\rm{tr}(AA^*)^3}{m^2}\right)^{1/6}+2\left(\frac{\rm{tr}(AA^*)}{m}\right)^{1/2}.
    \]
\end{lemma}
\begin{proof}
    This is Lemma 4.2 from Guth-Maynard. \cite{}
\end{proof}
Applying this lemma, we can compute that \[
    \rm{tr}(MM^*) =\sum_{n\sim N} \sum_{t\in W} \omega\left(\frac{n}{N}\right)^2 n^{-it} n^{it}= |W|\sum_n \omega\left(\frac{n}{N}\right)^2.
\]
Applying Poisson summation, this equals \[
    |W|\sum_m N \hat{h}_0(mN).
\]
By non-stationary phase use the rapid decay of $\hat{h}_0(\xi)$ in $\xi$ to only consider the term $m=0$ at the cost of $N^{-100}$.
Therefore, $\rm{tr}(MM^*)=|W|N\|\omega\|_{L_2}^2+O(N^{-100})$.
Lemma \ref{gmtrace} gives \[
|W|\ll NV^{-2}(N+(S_0+S_1+S_2+S_3-N^3|\omega|_{L_2}^6|W|)^{1/3}) \ll N^2V^{-2}+  NV^{-2}(S_1+S_2+S_3)^{1/3}. 
\]


\subsubsection*{5. Bounding $S_1$}
By symmetry in $m_1,m_2,m_3$, we can consider the terms where $m_3\neq 0$ at a cost of a factor of $3$.
Then \[
S_1 =3 N^3\sum_{m\neq 0} \sum_{t_1,t_2,t_3\in W}\hat{h}_{t_1-t_3}(0)\hat{h}_{t_2-t_1}(0)\hat{h}_{t_3-t_2}(mN).
\] 
This term is bounded by non-stationary phase. If $|m|>T^{1+\epsilon}/N$, then $|m|/|t_3-t_2|< T^\epsilon$, so we can truncate the sum to $|m|\leq T^{1+\epsilon}/N$ with an error of $O_\epsilon(T^{-100})$. In this range, if $t_1\neq t_3$ or $t_2\neq t_1$, then they are $T^\epsilon$ apart, then we get rapid decay in $\hat{h}_{t_1-t_3}(0)$ or $\hat{h}_{t_2-t_1}(0)$ to be $O_\epsilon{T^{-100}}$. But when $t_1=t_2=t_3$, we get decay in the last term $\hat{h}_0(mN)$. Combining all cases, this term is negligible.

\subsubsection*{6. Bounding $S_2$}

By symmetry again we can consider the terms where $m_1,m_2\neq 0,m_3=0$.Then \begin{align*}
    S_2=&3 N^3\sum_{m_1,m_2\neq 0} \sum_{t_1,t_2,t_3\in W}\hat{h}_{t_1-t_3}(m_1N)\hat{h}_{t_2-t_1}(m_2N)\hat{h}_{t_3-t_2}(0).
\end{align*}
Due to decay of the last term in $|t_3-t_2|$, we can only consider the terms $t_3=t_2$ with error $O_{\epsilon,A}(T^{-A})$. Then we can rewrite
\begin{align*}
    3 N^3\hat{h}_{0}(0)\sum_{m_1,m_2\neq 0} \sum_{t_1,t_2\in W}\hat{h}_{t_1-t_2}(m_1N)\hat{h}_{t_2-t_1}(m_2N) &= 3 N^3\hat{h}_{0}(0)\sum_{m_1,m_2\neq 0} \sum_{t_1,t_2\in W}\hat{h}_{t_1-t_2}(m_1N)\hat{h}_{t_1-t_2}(-m_2N)\\
    &= 3 N^3\hat{h}_{0}(0)\sum_{t_1,t_2\in W}\left(\sum_{m\neq 0}\hat{h}_{t_1-t_2}(mN)\right)^2.
\end{align*}
Poisson summation gives \[
N \sum_m \hat{h}_{t_1-t_2}(mN) = \sum_n h_{t_1-t_2}\Big(\frac{n}{N}\Big)=\sum_{n} \omega\left(\frac{n}{N}\right) n^{i(t_1-t_2)}.
\]
Therefore, a direct application of Heath Brown's theorem \ref{heathbrown} gives a bound for $S_2$.
    Here we have added in the terms for $m=0$, which is insignificant when $t_1$ and $t_2$ are $T^\epsilon$ separated. However, this is somewhat lossy for terms $t_1=t_2$. However, we can ignore the terms with $t_1=t_2$ at a small error due to the rapid decay in $\hat{h}_{t_1-t_2}(mN)$, apply Poisson summation, then add the terms $t_1=t_2$ again.

\subsubsection*{7. Bounding $S_3$}
$S_3$ sums over most points on the $3$-dimensional lattice. By symmetry, we can consider only the terms with $|m_1|\leq |m_2|\leq |m_3|$ with an error factor of $6$.
Recall that \[
I_m=N^3\sum_{t_1,t_2,t_3\in W}\hat{h}_{t_1-t_3}(Nm_1)\hat{h}_{t_2-t_1}(Nm_2)\hat{h}_{t_3-t_2}(Nm_3).
\]
By the the principle of non-stationary phase, we can truncate the sum across $I_m$ to $|m_1|,|m_2|,|m_3|\lesssim T/N$, at the cost of $O\epsilon(T^{-100})$, as $t_j-t_k=O(T)$.
We expand $\hat{h}$ in integral form, so that \begin{align*}
    I_{\vec{m}}&=N^3\sum_{t_1,t_2,t_3\in W}\int_{\reals^3} \omega(u_1)^2\omega(u_2)^2\omega(u_3)^2 u_1^{i(t_1-t_3)}u_2^{i(t_2-t_1)}u_3^{i(t_3-t_2)} e(-N\vec{m}\cdot \vec{u}) d\vec{u}\\ &=N^3\sum_{t_1,t_2,t_3\in W}\int_{\reals^3} \tilde{\omega}(\vec{u}) \Big(\frac{u_1}{u_2}\Big)^{it_1}\Big(\frac{u_2}{u_3}\Big)^{it_2}\Big(\frac{u_3}{u_1}\Big)^{it_3}e(-N\vec{m}\cdot \vec{u}) d\vec{u}
\end{align*}
For $\tilde{\omega}(\vec{u})=\omega(u_1)^2\omega(u_2)^2\omega(u_3)^2$. Because $\tilde{\omega}$ is supported away from $u_3=0$, we can introduce the change of variables $v_1=u_1/u_3$, $v_2=u_2/u_3$. The Jacobian is $u_3^2$, and $u_1/u_2=v_1/v_2$, so that \begin{align*}
    I_{\vec{m}}& = N^3\sum_{t_1,t_2,t_3\in W}\int_{\reals^3} u_3^2 \tilde{\omega}(v_1u_3,v_2u_3,u_3) \Big(\frac{v_1}{v_2}\Big)^{it_1} v_2^{it_2}\Big(\frac{1}{v_1}\Big)^{it_3}e(-Nu_3(m_1v_1+m_2v_2+m_3)) dv_1\ dv_2 \ du_3\\ 
    & = N^3\sum_{t_1,t_2,t_3\in W}\int_{\reals^2}\int_{\reals} u_3^2 \tilde{\omega}(v_1u_3,v_2u_3,u_3)e(-Nu_3(m_1v_1+m_2v_2+m_3))   du_3 \  \Big(\frac{v_1}{v_2}\Big)^{it_1} v_2^{it_2}\Big(\frac{1}{v_1}\Big)^{it_3}  dv_1\ dv_2 
\end{align*}
The inner integral in $u_3$ places restrictions on the domain of integration. First, the support of $\tilde{\omega}$ is $[1,2]\times [1,2]\times [1,2]$. Thus, if it is non-zero, we have $v_1u_3,v_2u_3,u_3\in [1,2]\implies v_1,v_2\in [1/2,2]$. Therefore, we can restrict the outer integral in $v_1$ and $v_2$ to this range. Next, since $v_1,v_2=O(1)$, the chain rule gives\[
\left(\frac{\partial}{\partial u_3}\right)^j{\omega}(v_1u_3,v_2u_3,u_3)\ll_j 1.\]
Therefore, we can apply the repeated integration by parts to get rapid decay of the integral in $|N(m_1v_1+m_2v_2+m_3)|$. In particular, we can truncate the integral to the range $|N(m_1v_1+m_2v_2+m_3)|\ll T^\epsilon$ at an error of $O_{\epsilon}(T^{-100})$, and use \[
    \int_{\reals} u_3^2 \tilde{\omega}(v_1u_3,v_2u_3,u_3)e(-Nu_3(m_1v_1+m_2v_2+m_3))   du_3=O(1)
\]
in this range by the compact support of $\tilde{\omega}$. This gives us \begin{equation}
    |I_{\vec{m}}|\leq \Bigg|N^3 \sum_{t_1,t_2,t_3\in W}\int\displaylimits_{\substack{
        |v_1m_1+v_2m_2+m_3|\lesssim \frac{1}{N}\\
        \frac{1}{2}\leq v_1,v_2\leq 2
    }} \Big(\frac{v_1}{v_2}\Big)^{it_1} v_2^{it_2}\Big(\frac{1}{v_1}\Big)^{it_3}  dv_1\ dv_2 \Bigg|+O_{\epsilon}(T^{-100}).
\end{equation}
Recall that in the outline we defined\[
R(v)\defeq\sum_{t\in W} v^{it}.
\]
Exchanging the summation and integral, we get the term \begin{align*}
    &\Bigg| N^3 \int\displaylimits_{\substack{
        |v_1m_1+v_2m_2+m_3|\lesssim \frac{1}{N}\\
        \frac{1}{2}\leq v_1,v_2\leq 2
    }} R\Big(\frac{v_1}{v_2}\Big) R({v_2}\Big) R\Big(\frac{1}{v_1}\Big) dv_1\ dv_2 \Bigg|\\
    \leq & N^3 \int\displaylimits_{\substack{
        |v_1m_1+v_2m_2+m_3|\lesssim \frac{1}{N}\\
        \frac{1}{2}\leq v_1,v_2\leq 2
    }} \Bigg|R\Big(\frac{v_1}{v_2}\Big) R({v_2}\Big) R\Big(\frac{1}{v_1}\Big)\Bigg| dv_1\ dv_2 \\
    =  & N^3 \int\displaylimits_{\substack{
        |v_1m_1+v_2m_2+m_3|\lesssim \frac{1}{N}\\
        \frac{1}{2}\leq v_1,v_2\leq 2
    }} \Bigg|R\Big(\frac{v_2}{v_1}\Big) R({v_2}\Big) R({v_1})\Bigg| dv_1\ dv_2,
\end{align*}
where the last step, we used \[
|R(v^{-1})| = \Big|\sum_{t\in W} v^{-it}\Big| = \Big|\sum_{t\in W} v^{it}\Big| = |R(v)|.
\]
Now we fix $v_1$, and consider the integral in $v_2$ in the range \[
    |v_1m_1+v_2m_2+m_3|\lesssim \frac{1}{N} \implies \Big|v_2 -\frac{v_1m_1+m_3}{-m_2}\Big|\lesssim \frac{1}{|m_2| N}.
\]
If we enforce the conditions $|m_1|\leq |m_2|\leq|m_3|$ and $v_2\asymp 1$, we see that the domain of integration is empty unless $|m_2|\asymp |m_3|$. Thus, we can break the sum across \[\sum_{|m_1|,|m_2|,|m_3|\lesssim T/N}\] to be \[\log T^{1+\epsilon}/N \ \rm{sup}_{U=2^j, V\leq U} \sum_{\substack{|m_1|\sim V\\  |m_2|, |m_3|\sim U}}.\]
Moreover, we integrate in $v_2$ over a very small neighborhood of width $\lesssim 1/(|m_2|N)$ around $v_2=({v_1m_1+m_3})/({-m_2})$. In principle, we can estimate this integral by taking the value of $R$ at this point to get \[
    \approx  \frac{1}{|m_2|N} \int\displaylimits_{\substack{
        \frac{1}{2}\leq v_1\leq 2
    }} \Bigg|R\Big(\frac{v_1m_1+m_3}{-v_1m_2}\Big) R(\frac{v_1m_1+m_3}{-m_2}\Big) R({v_1})\Bigg| dv_1.
\]
This is made precise by apply to a $(1/N|m_2|)$-smoothened version of $R$, stated in Proposition \ref{dyadics_3}. Finally, H\"older's inequality gives a bound of \begin{align*}
    \Big\|R\Big(\frac{vm_1+m_3}{-vm_2}\Big) \Big\|_{\substack{L_4\\ v\asymp 1}}\Big\|R\Big(\frac{vm_1+m_3}{-m_2}\Big) \Big\|_{\substack{L_4\\ v_1\asymp 1}}\Big\|R(v) \Big\|_{\substack{L_2\\ v_1\asymp 1}}
\end{align*}

The second moment of $R$ is bounded by the size of $W$. Indeed, we have \begin{align*}
    \int_{v\asymp 1} |R(v)|^2 dv =  \sum_{t_1,t_2\in W} \int_{v\asymp 1} v^{i(t_1-t_2)} dv.  
\end{align*}
If $t_1-t_2\neq 0$, then $|t_1-t_2|>T^\epsilon$, so the oscillatory integral will be negligible by the fast decay. There are $|W|$ terms satisfying $t_1=t_2$, and each contributes $O(1)$ to the sum. Similarly, the fourth moment of $R$ is bounded by the energy, recalling its definition \[
    E(W)\defeq \#\{t_1,t_2,t_3,t_4\in W : |t_1+t_2-t_3-t_4|\ll T^\epsilon\}.
\]
We get
\begin{align*}
    \int_{v\asymp 1} |R(v)|^4 dv =   \sum_{t_1,t_2,t_3,t_4\in W} \int_{v\asymp 1}  v^{i(t_1+t_2-t_3-t_4)} dv, 
\end{align*}
and the terms in the summation are negligble unless $|t_1+t_2-t_3-t_4|\ll T^\epsilon$. Assembling everything together gives an initial bound of \[
S_3\lesssim N^3\sum_{|m_1|\sim V ,|m_2|\sim V, |m_3|\sim V}\frac{1}{|m_2|N}E(W)^{1/2}|W|^{1/2}\lesssim T^2E(W)^{1/2}|W|^{1/2},
\]
recalling that $U,V\lesssim T/N$.


\subsubsection*{9. Refinement of $S_3$ bound}

Recall that in the previous section, we summed across 
\[
    \sum_{\substack{|m_1|\sim V\\ |m_2|, |m_3|\sim U}} \frac{N}{|m_2|} \int\displaylimits_{\substack{
        \frac{1}{2}\leq v_1\leq 2
    }} \Bigg|R\Big(\frac{v_1m_1+m_3}{-v_1m_2}\Big) R\Big(\frac{v_1m_1+m_3}{-m_2}\Big) R({v_1})\Bigg| dv_1
\]
By repeatedly applying Cauchy-Schwartz, we can move the summation into the integral and obtain terms that resembles the form \[
   \int_{v_1\asymp 1} \Bigg(\sum_{\substack{|m_1|\sim V\\ |m_2|, |m_3|\sim U}}  \Big| R\Big(\frac{v_1m_1+m_3}{-m_2}\Big)\Big|^2\Bigg)^2 dv_1.
\]
The term $(v_1m_1+m_3)/(-m_2)$ describes an affine transformation in $v_1$. Intuitively, thus averaging over all the affine transformations is can be expressed as the expected value of a random variable squared, where the random variable \[
X\defeq X(v_1)\defeq \sum_{\substack{|m_1|\sim V\\ |m_2|, |m_3|\sim U}}  \Big| R\Big(\frac{v_1m_1+m_3}{-m_2}\Big)\Big|^2,
\] and the measure is uniform across $v_1\asymp 1$. This can be split up to get \[
E[X^2] = E[X]^2 + \rm{Var}(X).
\] Indeed, we have Lemma \ref{affinetransgm} that gives us this estimate. 
By a change of variables, the expected value of $X$ is represented by $M^3 \int_{u\asymp 1} R(u)^2 du$.
\begin{lemma}\label{affinetransgm}
    Let $M>0$. Let $f(u)\geq 0$, supported on $u\asymp 1$, and $|\hat{f}(\xi)|\lesssim_j (|\xi|/T)^j$ for all $j$. Then \begin{align*}
        J(f)\defeq &\sup_{0<M_1,M_2,M_3<M} \int\Bigg( \sum_{\substack{|m_1|\sim M_1,|m_2|\sim M_2 , |m_3|\ll M_3}} f\left(\frac{m_1 u+m_3}{m_2}\right)\Bigg)^2 \ du\\
        \lesssim&M^6\Big( \int f(u) du\Big)^2+M^4 \int f(u)^2 du.
    \end{align*}
\end{lemma}
This is Proposition 9.1 in \cite{GM2024}.
This improves the bound on $S_3$ to\[
S_3\lesssim T^2|W|^{3/2}+TN|W|^{1/2}E(W)^{1/2}.
\]
This gives an improvement from the previous bound for the case with high energy and $N<T^{1-\delta}$.
\begin{remark}
    The proof to Lemma \ref{affinetransgm} does not use probability. Instead, it applies Plancherel's theorem on $\sum_{m_1,m_2,m_3} f$ and bounds in the Fourier domain.
    At low frequencies, this can be bounded by the $L_1$ norm of $f$. At high frequencies, the Fourier transform of $f$ decays rapidly. Finally, at mid frequencies, the integral relates to \[
     (M^4\int f^2 du)^{1/2}J(f)^{1/2},
    \]
    by Cauchy Schwarz and a change of variables to decouple $m_1$ and $m_2$, providing the required bound by backward induction.
\end{remark}

\subsubsection*{8. Bound on $E(W)$}
Finally, we give an orthogonal bound on the energy of the set $W$. The idea is that if $|t_1+t_2-t_3-t_4|$ is small, then we can approximate \[
D_N(t_4) \approx D_N(t_1+t_2-t_3).
\]
This is made precise by applying a smoothing of $D_N$ over a width of $\lesssim 1$.
Therefore, since the choice of $t_4$ is fixed by the choice of $t_1,t_2,t_3$, we have\[
E(W)V^2\leq \sum_{|t_1-t_2-t_3-t_4|\lesssim 1} |D_N(t_4)|^2 \approx \sum_{|t_1-t_2-t_3-t_4|\lesssim 1} |D_N(t_1+t_2-t_3)|^2 \leq \sum_{t_1,t_2,t_3\in W} |D_N(t_1+t_2-t_3)|^2.
\]
Now we can expand $|D_N(t_1+t_2-t_3)|^2$ to get \begin{align*}
    \sum_{t_1,t_2,t_3\in W} |D_N(t_1+t_2-t_3)|^2=& \sum_{t_1,t_2,t_3\in W}\sum_{n_1,n_2\sim N} b_{n_1} \bar{b}_{n_2} \Big(\frac{n_1}{n_2}\Big)^{i(t_1+t_2-t_3)}\\ 
    =&\sum_{n_1,n_2\sim N} b_{n_1} \bar{b}_{n_2}\sum_{t_1,t_2,t_3\in W}\Big(\frac{n_1}{n_2}\Big)^{i(t_1+t_2-t_3)}\\ 
    \leq& \sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)R\Big(\frac{n_1}{n_2}\Big)R\Big(\frac{n_2}{n_1}\Big)\Big|\\ 
    \leq& \sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^3.
\end{align*}
Now we can apply the trivial bound $|R|\leq |W|$ to get that \[
    E(W)\lesssim V^{-2}|W|\sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^2.
\]
This is in turn bounded by Heath-Brown's result as \begin{align*}
    \sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^2 &=
    \sum_{n_1,n_2\sim N}\sum_{t_1,t_2\in W} \Big(\frac{n_1}{n_2}\Big)^{i(t_1-t_2)}\\ 
    &= \sum_{t_1,t_2\in W} \Big|\sum_{n\sim N} n^{i(t_1-t_2)} \Big|^2\\
    &\lesssim |W|N^2+|W|^2N+|W|^{5/4}T^{1/2}N.
\end{align*}
This is enough to give an improvement on Ingham-Huxley's result, but can be further improved using Cauchy Schwartz on the third moment \begin{align*}
    \sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^3 \leq 
    \Bigg(\sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^2 \Bigg)^{1/2} \Bigg(\sum_{n_1,n_2\sim N} \Big|R\Big(\frac{n_1}{n_2}\Big)\Big|^4\Bigg)^{1/2}.
\end{align*}
The fourth moment can be reduced back to the second moment by taking representative classes of $\lfloor t_1-t_2 \rfloor$, thus can also be bounded using Heath-Brown's result. 